# INT-006: Add Logging to swarm.py

**Lane**: INTEGRATION  
**Type**: ADD_METRIC  
**Priority**: MEDIUM  
**Status**: PENDING  
**Created**: 2026-01-15

---

## Problem Statement

The swarm.py script performs critical state mutations and operations with no logging or audit trail. State changes, wave increments, task collection, and result processing occur silently, making it impossible to:

1. **Debug operational issues** - No record of what commands were executed
2. **Audit state changes** - Cannot track when/how STATE.json was modified
3. **Monitor swarm health** - No visibility into task collection and wave progression
4. **Troubleshoot failures** - Silent failures leave no trace for investigation

---

## Context Pack: Key Functions Needing Logging

### Function 1: load_state() (Lines 12-16)
```python
def load_state():
    if not STATE_FILE.exists():
        return {"wave": 0, "active_zerglings": [], ...}
    with open(STATE_FILE) as f:
        return json.load(f)
```
**Needs**: Log file load events and state initialization

### Function 2: save_state() (Lines 18-21)
```python
def save_state(state):
    state["last_updated"] = datetime.now().isoformat()
    with open(STATE_FILE, 'w') as f:
        json.dump(state, f, indent=2)
```
**Needs**: Log every state mutation with timestamp and changed fields

### Function 3: cmd_wave() (Lines 38-41)
```python
def cmd_new_wave():
    state = load_state()
    state['wave'] += 1
    save_state(state)
    print(f"Wave incremented to: {state['wave']}")
```
**Needs**: Log wave increment with before/after values

### Function 4: cmd_collect() (Lines 52-66)
```python
def cmd_collect():
    if not INBOX_DIR.exists():
        return
    results = list(INBOX_DIR.glob("*.md"))
    state = load_state()
    collected = 0
    for result in results:
        task_id = result.stem
        if task_id not in state.get('completed_tasks', []):
            state.setdefault('completed_tasks', []).append(task_id)
            collected += 1
        if task_id in state.get('pending_tasks', []):
            state['pending_tasks'].remove(task_id)
    save_state(state)
```
**Needs**: Log each collected result, task transitions, and collection summary

---

## Critical Flaw Identified

### MEDIUM: No Logging - Script Performs State Mutations with No Audit Trail

**Risk**: State changes occur silently without any record  
**Impact**: 
- Cannot debug when commands fail or behave unexpectedly
- No visibility into state changes over time
- Impossible to audit who/when state was modified
- Swarm progress untracked in operational logs

**Severity**: MEDIUM (not critical because errors still fail/crash, but operational visibility is lost)

---

## Deliverables

### D1: Setup Python Logging
- Import logging module
- Configure logger at module level: `logger = logging.getLogger(__name__)`
- Set format: `%(asctime)s - %(name)s - %(levelname)s - %(message)s`
- Create logs directory: `/home/ubuntu/projects/zerg-swarm/SWARM/LOGS/`
- Configure file handler to write to: `SWARM/LOGS/swarm.log`
- Set logging level to DEBUG for capture, but INFO for normal output

### D2: Add Logging to save_state()
- Log before write: `logger.info(f"Saving state: wave={state.get('wave')}, pending={len(state.get('pending_tasks', []))}, completed={len(state.get('completed_tasks', []))}") `
- Log after successful write: `logger.info(f"State saved successfully")`
- Include last_updated timestamp in log message

### D3: Add Logging to cmd_wave()
- Log wave transition: `logger.info(f"Wave increment: {old_wave} -> {new_wave}")`
- Include timestamp when wave was incremented

### D4: Add Logging to cmd_collect()
- Log before collection: `logger.debug(f"Starting result collection, {len(results)} items in INBOX")`
- Log each collected result: `logger.info(f"Collected result: {task_id}")`
- Log task state transitions: `logger.debug(f"Task {task_id}: pending -> completed")`
- Log collection summary: `logger.info(f"Collection complete: {collected} new results, total completed={len(state.get('completed_tasks', []))}") `

### D5: Add Logging to load_state()
- Log state file load: `logger.debug(f"Loading state from {STATE_FILE}")`
- Log default state creation: `logger.info(f"Creating default state: wave=0")`

---

## Implementation Requirements

### Required Changes to swarm.py (Top of file)

```python
#!/usr/bin/env python3
"""Zerg Rush Swarm Manager CLI"""
import json, sys, logging
from datetime import datetime
from pathlib import Path

# Setup logging
SWARM_ROOT = Path(__file__).parent.parent
LOGS_DIR = SWARM_ROOT / "LOGS"
LOGS_DIR.mkdir(exist_ok=True)

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# File handler
fh = logging.FileHandler(LOGS_DIR / "swarm.log")
fh.setLevel(logging.DEBUG)

# Formatter
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
fh.setFormatter(formatter)

# Add handler
logger.addHandler(fh)

# Rest of imports and constants...
```

### Updated save_state()

```python
def save_state(state):
    old_wave = state.get('wave', 0)
    old_pending = len(state.get('pending_tasks', []))
    old_completed = len(state.get('completed_tasks', []))
    
    state["last_updated"] = datetime.now().isoformat()
    logger.info(f"Saving state: wave={old_wave}, pending={old_pending}, completed={old_completed}, timestamp={state['last_updated']}")
    
    with open(STATE_FILE, 'w') as f:
        json.dump(state, f, indent=2)
    
    logger.debug(f"State written to {STATE_FILE}")
```

### Updated cmd_new_wave()

```python
def cmd_new_wave():
    state = load_state()
    old_wave = state['wave']
    state['wave'] += 1
    logger.info(f"Wave increment: {old_wave} -> {state['wave']}")
    save_state(state)
    print(f"Wave incremented to: {state['wave']}")
```

### Updated cmd_collect()

```python
def cmd_collect():
    if not INBOX_DIR.exists():
        logger.warning(f"INBOX doesn't exist at {INBOX_DIR}")
        print("INBOX doesn't exist, nothing to collect")
        return
    
    results = list(INBOX_DIR.glob("*.md"))
    logger.debug(f"Found {len(results)} results in INBOX")
    
    if not results:
        logger.info("No results to collect")
        print("No results to collect")
        return
    
    state = load_state()
    collected = 0
    
    for result in results:
        task_id = result.stem
        if task_id not in state.get('completed_tasks', []):
            state.setdefault('completed_tasks', []).append(task_id)
            logger.info(f"Collected result: {task_id}")
            collected += 1
        
        if task_id in state.get('pending_tasks', []):
            state['pending_tasks'].remove(task_id)
            logger.debug(f"Task {task_id}: pending -> completed")
    
    save_state(state)
    logger.info(f"Collection complete: {collected} new results collected, total completed={len(state.get('completed_tasks', []))}")
    print(f"Collected {collected} new results")
    print(f"Total completed: {len(state.get('completed_tasks', []))}")
```

### Updated load_state()

```python
def load_state():
    if not STATE_FILE.exists():
        logger.info(f"Creating default state (STATE_FILE not found at {STATE_FILE})")
        return {
            "wave": 0,
            "active_zerglings": [],
            "completed_tasks": [],
            "pending_tasks": [],
            "last_updated": datetime.now().isoformat()
        }
    
    logger.debug(f"Loading state from {STATE_FILE}")
    with open(STATE_FILE) as f:
        state = json.load(f)
    logger.debug(f"State loaded: wave={state.get('wave')}, pending={len(state.get('pending_tasks', []))}, completed={len(state.get('completed_tasks', []))}")
    return state
```

---

## Verification Command

Run these commands to verify logging is working:

```bash
# Test 1: Check that logs directory is created
ls -la /home/ubuntu/projects/zerg-swarm/SWARM/LOGS/

# Test 2: Run status command and check logs
cd /home/ubuntu/projects/zerg-swarm/SWARM
python3 SCRIPTS/swarm.py status
tail -20 /home/ubuntu/projects/zerg-swarm/SWARM/LOGS/swarm.log
# Expected: Log entries showing state load, optional commands

# Test 3: Increment wave and verify logging
python3 SCRIPTS/swarm.py wave
tail -20 /home/ubuntu/projects/zerg-swarm/SWARM/LOGS/swarm.log
# Expected: Log entries showing "Wave increment: X -> Y"

# Test 4: Create test result and collect
mkdir -p /home/ubuntu/projects/zerg-swarm/SWARM/INBOX
echo "test result" > /home/ubuntu/projects/zerg-swarm/SWARM/INBOX/TEST-001.md
python3 SCRIPTS/swarm.py collect
tail -30 /home/ubuntu/projects/zerg-swarm/SWARM/LOGS/swarm.log
# Expected: Log entries showing "Collected result: TEST-001", "Collection complete:"

# Test 5: Verify log format (should show timestamp, logger name, level, message)
grep -E "INFO|DEBUG" /home/ubuntu/projects/zerg-swarm/SWARM/LOGS/swarm.log | head -5
# Expected: Lines matching format "YYYY-MM-DD HH:MM:SS,mmm - swarm - INFO/DEBUG - message"
```

---

## Acceptance Criteria

- [ ] Logging module imported and configured
- [ ] LOGS directory created at SWARM/LOGS/
- [ ] swarm.log file created after first command run
- [ ] save_state() logs every state mutation with wave/pending/completed counts
- [ ] cmd_wave() logs wave transitions with before/after values
- [ ] cmd_collect() logs each collected result and provides summary
- [ ] load_state() logs state load and default creation
- [ ] All log messages include timestamp (handled by logging formatter)
- [ ] Log level is DEBUG (captures all messages)
- [ ] Verification command tests all 5 scenarios pass
- [ ] No new exceptions introduced by logging code

---

## Reference Files

- **Source**: `/home/ubuntu/projects/zerg-swarm/SWARM/SCRIPTS/swarm.py`
- **Log Output**: `/home/ubuntu/projects/zerg-swarm/SWARM/LOGS/swarm.log` (created during execution)
- **Related**: INT-002 (error handling), INT-001 (directory structure)

---

## Notes

- Logging is NON-INTRUSIVE - only adds import and logger setup, does not change command behavior
- Log messages use appropriate levels: INFO for state changes, DEBUG for flow control, WARNING for missing directories
- Logs persist to disk for audit trail and post-mortem analysis
- Log format matches standard Python logging conventions for easy parsing
- LOGS directory must exist before logging first write (handled with mkdir(exist_ok=True))
